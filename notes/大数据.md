#### 1. 为什么很多公司选择Hadoop作为大数据平台的解决方案？

- 源码开元
- 社区活跃、参与者很多
- 涉及到分布式存储和计算的方方面面：Flume进行数据采集、Spark/MR/Hive等进行数据处理、HDFS/HBASE数据存储

#### 2. HDFS架构

- 1个Master（NameNode）带N个Slaves（DataNode）
- NameNode：负责客户端请求的响应；负责元数据（文件的名称、副本系数、Block存放的DataNode的地址）的管理
- DataNode：存储用户的文件对应的数据块；要定期向NameNode发送心跳信息，汇报本身及其所有的block信息，健康状况

#### 3. HDFS常用命令

- hadoop fs [generic options]
- 查看目录：hadoop fs -ls  /、hadoop fs -ls -R /
- 创建文件夹：hadoop fs -mkdir /test/
- 创建多层目录：hadoop fs -mkdir -p /a/b
- 上传文件：hadoop fs -put filename /test/
- 查看文件内容：hadoop fs -text /test/filename
- 下载文件：hadoop fs -get /test/filename newfile
- 删除文件：hadoop fs -rm /test/filename
- 删除目录：hadoop fs -rm -r /a

#### 4. HDFS优缺点：

- 优点：
  - 高容错
  - 适合批处理
  - 适合大数据处理
  - 可构建在廉价机器上
- 缺点：
  - 满足不了低延迟的数据访问(HBASE解决)
  - 不适合小文件存储

#### 5. MapReduce(离线批处理)

- 特点：
  - 易于编程
  - 良好的扩展性
  - 高容错性
  - 海量数据的离线处理
- MapReduce不擅长的场景：
  - 实时计算
  - 流式处理
  - DAG计算
- 编程模型：
  - input
  - map&reduce
  - output
- 局限性：
  - 代码繁琐
  - 只能够支持map和reduce方法
  - 执行效率低下
  - 不合适迭代多次、交互式、流式处理

#### 6. YARN(资源调度框架)

- 架构：1 Resource Manager + N Node Manager
- Resource Manager职责：一个集群中只有一个Resource Manager处于活跃状态，负责整个集群的资源管理和调度
  - 处理客户端的的请求(启动、杀死)
  - 启动/监控Application Master（一个作业对应一个Application Master）
  - 监控Node Manager
  - 系统的资源分配和调度
- Node Manager职责：整个集群中有N个，负责单个节点的资源管理和使用以及task的运行情况
  - 定期向Resource Manager汇报本节点的资源使用情况和各个Container的运行状态
  - 接受并处理Resource Manager的container的启停的各种命令
  - 单个节点的资源管理和任务管理
- Application Master：每个应用/作业对应一个，负责应用程序的管理
  - 数据切分
  - 为应用程序向Resource Manager申请资源(container)，并分配给内部任务
  - 与Node Manager通信以启停task，task是运行在container中的
  - task的监控和容错
- Container：对任务运行情况的描述(cpu、memory、环境变量)
- YARN执行流程：
  - 用户向YARN提交作业
  - Resource Manager为该作业分配第一个container(Application Master)
  - Resource Manager与对应的Node Manager通信，要求Node Manager在这个container上启动应用程序的Application Master
  - Application Master首先会向Resource Manager注册，然后Application Manager将为各个任务申请资源，并监控运行情况
  - Application Master采用轮询的方式通过RPC协议向Resource Manager申请和领取资源
  - Application申请到资源以后，便和相应的Node Manager通信，要求Node Manager启动任务
  - Node Manager启动作业对应的task

#### 7. Hive

- 产生背景：
  - MapReduce编程的不便性
  - HDFS上的文件缺少Schema
- 为什么使用Hive：
  - 简单、容易上手(提供了类似SQL查询语言HQL)
  - 为超大数据集设计的计算/存储扩展能力(MR计算、HDFS存储)
  - 统一的元数据管理(可与Presto/Impala/SparkSQL等共享数据)

#### 8. Spark

- Speed
- Ease of Use
- Generality
- Runs Everywhere
- Spark Standalone模式：1 master + n worker

#### 9. SQL on Hadoop

- Hive
  - sql ===> mapreduce
  - metastore:元数据
  - sql: database、table、view
  - facebook
- impala
  - cloudera：cdh(建议大家在生产上面使用的hadoop系列版本)、cm
  - sql：自己的守护进程，非mr，基于内存
  - metastore：元数据
- presto：
  - facebook开源
  - sql
- drill：
  - sql
  - 访问：hdfs、rdbms、json、hbase、mongodb、s3、hive
- Spark SQL：
  - sql
  - dataframe/dataset spi
  - metastore
  - 访问：hdfs、rdbms、json、hbase、mongodb、s3、hive
  - 总结：应用不局限于SQL；访问hive、json、parwuet等文件的数据；SQL只是Spark SQL的一个功能；Spark SQL提供了SQL的api、DataFrame和DataSet的api

